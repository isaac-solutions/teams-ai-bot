# Dropbox RAG Integration - Project Overview

## What This System Does

This system automatically processes files from Dropbox and makes them searchable using AI-powered semantic search (RAG - Retrieval-Augmented Generation).

**In Simple Terms:**
1. You point it at a Dropbox folder
2. It downloads and processes all documents (PDF, DOCX, PPTX, etc.)
3. It converts them to searchable text with AI embeddings
4. Your agents (or users) can search across all documents using natural language

## Architecture at a Glance

```
Dropbox Files â†’ Backend API â†’ Queue â†’ Worker â†’ MongoDB
                                        â†“
                          Agent Search â† RAG API
```

### Components

1. **Backend API** (FastAPI)
   - Endpoints to sync files from Dropbox
   - Endpoints to search documents
   - Manages job queue

2. **Worker** (Python)
   - Converts documents to markdown (docling)
   - Creates text chunks
   - Generates AI embeddings (Azure OpenAI)
   - Stores in MongoDB

3. **Storage**
   - MongoDB: Stores document chunks with embeddings
   - Azure Blob: Stores original files and markdown
   - Azure Service Bus: Job queue

## Key Features

### Document Processing
- **Supported**: PDF, DOCX, PPTX, TXT, MD, HTML, CSV, XLSX
- **Conversion**: High-quality markdown using docling
- **Chunking**: Smart text splitting (512 tokens, 50 overlap)
- **Deduplication**: Skip unchanged files (hash-based)

### Search Capabilities
- **Semantic Search**: Find documents by meaning, not just keywords
- **Filters**: By file type, date, specific files
- **Ranked Results**: Sorted by relevance score
- **Source Attribution**: Know exactly which file and section

### For Your Agents
- **REST API**: Easy integration with any agent framework
- **JSON Responses**: Structured data ready to use
- **Context-Aware**: Get relevant document chunks with metadata

## Data Flow

### Ingestion Flow
```
1. POST /api/dropbox/sync {"path": "/Documents"}
   â†“
2. Backend lists files from Dropbox
   â†“
3. Downloads to Azure Blob Storage
   â†“
4. Creates database record
   â†“
5. Sends job to queue
   â†“
6. Worker picks up job
   â†“
7. Converts to markdown (docling)
   â†“
8. Chunks text intelligently
   â†“
9. Generates embeddings (Azure OpenAI)
   â†“
10. Stores in MongoDB
```

### Search Flow
```
1. POST /api/rag/search {"query": "revenue forecast"}
   â†“
2. Generate embedding for query
   â†“
3. Vector search in MongoDB
   â†“
4. Rank by similarity
   â†“
5. Return top results with source info
```

## MongoDB Collections

### `dropbox_files`
Tracks each processed file:
```javascript
{
  "_id": ObjectId,
  "filename": "Q4_Report.pdf",
  "dropbox_path": "/Documents/Q4_Report.pdf",
  "processing_status": "completed",
  "chunk_count": 45,
  "file_hash": "abc123...",
  "created_at": ISODate,
  "updated_at": ISODate
}
```

### `dropbox_chunks`
Stores searchable chunks:
```javascript
{
  "_id": ObjectId,
  "file_id": ObjectId("..."),
  "chunk_index": 12,
  "content": "Revenue increased by 25%...",
  "embedding": [0.123, -0.456, ...],  // 3072 dimensions
  "metadata": {
    "chunk_type": "text",
    "token_count": 485
  }
}
```

## API Examples for Agents

### Sync Files
```bash
POST /api/dropbox/sync
{
  "path": "/Company Documents",
  "recursive": true,
  "file_types": ["pdf", "docx"]
}
```

### Search Documents
```bash
POST /api/rag/search
{
  "query": "What was mentioned about revenue in Q4?",
  "top_k": 5,
  "file_types": ["pdf"]
}

Response:
{
  "results": [
    {
      "filename": "Q4_Report.pdf",
      "content": "Revenue increased by 25%...",
      "score": 0.89,
      "chunk_index": 12
    }
  ]
}
```

### Check File Status
```bash
GET /api/dropbox/files?status=completed&page=1
```

## Local Testing Workflow

### Test Docling Conversion First
```bash
cd worker
python test_worker_local.py --file "sample.pdf"
```

This outputs:
- `sample.md` - Converted markdown
- `sample_chunks.json` - Chunked content
- `sample_summary.txt` - Statistics

Review these to ensure conversion quality meets your needs.

### Run Full System
```bash
# Terminal 1: Backend
cd backend
python -m uvicorn main:app --reload

# Terminal 2: Worker
cd worker
python main.py

# Terminal 3: Test
curl -X POST http://localhost:8000/api/dropbox/sync \
  -H "Content-Type: application/json" \
  -d '{"path": "/Test"}'
```

## Cost Considerations

### Azure OpenAI Costs
- Text-embedding-3-large: $0.13 per 1M tokens
- Text-embedding-3-small: $0.02 per 1M tokens (cheaper, slightly less accurate)

**Example**: Processing 100 PDFs (avg 10 pages each):
- ~500,000 tokens
- Cost with large model: ~$0.07
- Cost with small model: ~$0.01

### Storage Costs
- Blob Storage: ~$0.02 per GB/month
- MongoDB Atlas: Starting at $0.08/hour (M10 cluster)
- Service Bus: Minimal for this use case

### Optimization Tips
- Use `text-embedding-3-small` for 50% cost reduction
- Increase chunk size to reduce number of embeddings
- Process only changed files (hash-based deduplication)

## Performance

### Processing Speed
| File Type | Pages/Slides | Time |
|-----------|-------------|------|
| PDF | 10 pages | ~45s |
| DOCX | 5000 words | ~30s |
| PPTX | 20 slides | ~60s |

### Scalability
- Worker scales horizontally (add more containers)
- Queue handles bursts automatically
- MongoDB Atlas auto-scales

## Integration with Agents

### Example: LangChain Agent
```python
import requests

def search_documents(query: str, top_k: int = 5):
    response = requests.post(
        "http://localhost:8000/api/rag/search",
        json={"query": query, "top_k": top_k}
    )
    return response.json()["results"]

# Use in agent
results = search_documents("What is our hiring policy?")
context = "\n".join([r["content"] for r in results])
agent.run(f"Based on this context: {context}\nAnswer: {user_question}")
```

### Example: AutoGPT Plugin
```python
@command(
    "search_documents",
    "Search company documents",
    {"query": "search query"}
)
def search_documents(query: str):
    response = requests.post(
        f"{RAG_API_URL}/api/rag/search",
        json={"query": query, "top_k": 5}
    )
    return response.json()
```

## Security Notes

### Required Configuration
- **Authentication**: Add auth middleware to backend
- **CORS**: Configure allowed origins
- **Secrets**: Use Azure Key Vault for production
- **Network**: Use private endpoints in production

### Data Privacy
- Files stored in your Azure Blob Storage
- Embeddings in your MongoDB instance
- No data sent to external services except Azure OpenAI (for embeddings)

## Development Roadmap

### Completed âœ…
- Document conversion (docling)
- Vector search
- Manual sync
- Multi-file-type support
- Local testing script
- Full documentation

### Future Enhancements ğŸš€
- Webhook support (auto-sync on file changes)
- Authentication/authorization
- File deletion handling
- Incremental updates
- Enhanced table extraction
- Multi-language support

## Getting Help

### Quick Start
â†’ See [QUICKSTART.md](QUICKSTART.md)

### Setup & Configuration
â†’ See [SETUP.md](SETUP.md)

### Full Documentation
â†’ See [README.md](README.md)

### Common Issues
1. **Worker not processing**: Check queue and logs
2. **Poor search results**: Verify vector index is created
3. **Conversion quality**: Test locally with `test_worker_local.py`
4. **Costs too high**: Switch to `text-embedding-3-small`

## Files Overview

```
dropbox-mongodb/
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ main.py                 # Worker processing logic
â”‚   â”œâ”€â”€ test_worker_local.py    # Local testing tool
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ env.example
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ deploy-worker.ps1       # Azure deployment
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ dropbox.py          # Sync & file management
â”‚   â”‚   â””â”€â”€ rag.py              # Search endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ dropbox_service.py  # Dropbox API
â”‚   â”‚   â””â”€â”€ queue_service.py    # Azure Service Bus
â”‚   â”œâ”€â”€ models/                 # Pydantic models
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ env.example
â”‚
â”œâ”€â”€ README.md                   # Full documentation
â”œâ”€â”€ SETUP.md                    # Detailed setup guide
â”œâ”€â”€ QUICKSTART.md               # 5-minute quick start
â”œâ”€â”€ PROJECT_OVERVIEW.md         # This file
â””â”€â”€ .gitignore
```

## Summary

This system turns your Dropbox files into an AI-powered knowledge base that your agents can query using natural language. It's production-ready, scalable, and cost-effective.

**Key Benefits:**
- âœ… Automatic document processing
- âœ… Semantic search (not just keywords)
- âœ… Easy agent integration
- âœ… Handles multiple file types
- âœ… Scalable architecture
- âœ… Local testing before deployment
- âœ… Complete documentation

**Get Started in 5 Minutes:** [QUICKSTART.md](QUICKSTART.md)

